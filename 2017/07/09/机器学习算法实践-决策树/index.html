<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>机器学习算法实践-决策树 | PytLab</title>
  <meta name="author" content="PytLab">
  
  <meta name="description" content="Personal Blog of ShaoZhengjiang">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="机器学习算法实践-决策树"/>
  <meta property="og:site_name" content="PytLab"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <link rel="alternative" href="/true" title="PytLab" type="application/atom+xml">
  
  
    <link href="/assets/images/favicon/icon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/bootstrap.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-73223373-1', 'auto');
  ga('send', 'pageview');
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

 <body>  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav id="main-nav" class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/"></a>
      <div class="collapse navbar-collapse nav-menu">
		    <ul class="nav navbar-nav">
		      

          <!-- Categories -->
          
          <li>
            <a href="/" title="PytLab's Home" style="font-weight: normal; font-family: Calibri,Arial; font-size: 18px">
              <i class="fa fa-bank"></i>Home
            </a>
          </li>
          
		      

          <!-- Categories -->
          
          <!-- Archives -->
          <li class="dropdown">
            <a href="/archives" class="dropdown-toggle" data-toggle="dropdown" title="All the articles." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
            <i class="fa fa-archive"></i>Archives
            <b class="caret"></b>   
            </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/archives" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Archives</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/2017/07/09/机器学习算法实践-决策树/" style="font-size: 15px; font-family: 微软雅黑">机器学习算法实践-决策树<span></span></a></li>
              
              <li><a href="/2017/07/04/KinLab-基于Flask-Bootstrap实现微观动力学计算的web应用/" style="font-size: 15px; font-family: 微软雅黑">KinLab - 基于Flask+Bootstrap实...<span></span></a></li>
              
              <li><a href="/2017/06/18/实现一个Bootstrap的JS插件/" style="font-size: 15px; font-family: 微软雅黑">编写Bootstrap插件的步骤<span></span></a></li>
              
              <li><a href="/2017/06/03/算法分析中的渐进记号总结/" style="font-size: 15px; font-family: 微软雅黑">算法分析中的渐近记号总结<span></span></a></li>
              
              <li><a href="/2017/04/25/基于matplotlib写一个2D-3D抽象网格和能量曲线绘制程序/" style="font-size: 15px; font-family: 微软雅黑">基于matplotlib的2D/3D抽象网格和能量曲线...<span></span></a></li>
              
              <li><a href="/2017/03/26/优雅的在终端中编写Python/" style="font-size: 15px; font-family: 微软雅黑">优雅的在终端中编写Python<span></span></a></li>
              
              <li><a href="/2017/02/19/Python多进程并行编程实践-mpi4py的使用/" style="font-size: 15px; font-family: 微软雅黑">Python多进程并行编程实践-mpi4py的使用<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
          </li>

          
		      

          <!-- Categories -->
          
		      <li class="dropdown">
            <a href="/categories" class="dropdown-toggle" data-toggle="dropdown" title="All the categories." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
		    	  <i class="fa fa-folder"></i>Categories
            <b class="caret"></b>   
		    	  </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/categories" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Categories</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/categories/学习小结/" style="font-size: 15px; font-family: 微软雅黑">学习小结<span></span></a></li>
              
              <li><a href="/categories/学术/" style="font-size: 15px; font-family: 微软雅黑">学术<span></span></a></li>
              
              <li><a href="/categories/代码作品/" style="font-size: 15px; font-family: 微软雅黑">代码作品<span></span></a></li>
              
              <li><a href="/categories/教程/" style="font-size: 15px; font-family: 微软雅黑">教程<span></span></a></li>
              
              <li><a href="/categories/我的日常/" style="font-size: 15px; font-family: 微软雅黑">我的日常<span></span></a></li>
              
              <li><a href="/categories/随笔/" style="font-size: 15px; font-family: 微软雅黑">随笔<span></span></a></li>
              
              <li><a href="/categories/工具应用/" style="font-size: 15px; font-family: 微软雅黑">工具应用<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
		      </li>

          
		      

          <!-- Categories -->
          
          <!-- Tags -->
          <li class="dropdown">
            <a href="/tags" class="dropdown-toggle" data-toggle="dropdown" title="All the tags." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
            <i class="fa fa-tags"></i>Tags
            <b class="caret"></b>   
            </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/tags" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Tags</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/tags/Cpp/" style="font-size: 15px; font-family: 微软雅黑">Cpp<span></span></a></li>
              
              <li><a href="/tags/python/" style="font-size: 15px; font-family: 微软雅黑">python<span></span></a></li>
              
              <li><a href="/tags/catalysis/" style="font-size: 15px; font-family: 微软雅黑">catalysis<span></span></a></li>
              
              <li><a href="/tags/C/" style="font-size: 15px; font-family: 微软雅黑">C<span></span></a></li>
              
              <li><a href="/tags/chemistry/" style="font-size: 15px; font-family: 微软雅黑">chemistry<span></span></a></li>
              
              <li><a href="/tags/Parallel-Computing/" style="font-size: 15px; font-family: 微软雅黑">Parallel Computing<span></span></a></li>
              
              <li><a href="/tags/学术/" style="font-size: 15px; font-family: 微软雅黑">学术<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
          </li>
          
          
		      

          <!-- Categories -->
          
          <li>
            <a href="/about" title="About me." style="font-weight: normal; font-family: Calibri,Arial; font-size: 18px">
              <i class="fa fa-user"></i>About
            </a>
          </li>
          
		      
		    </ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">		
			<h1> 机器学习算法实践-决策树</h1>
		</div>		
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近打算系统学习下机器学习的基础算法，避免眼高手低，决定把常用的机器学习基础算法都实现一遍以便加深印象。本文为这系列博客的第一篇，关于决策树(Decision Tree)的算法实现，文中我将对决策树种涉及到的算法进行总结并附上自己相关的实现代码。所有算法代码以及用于相应模型的训练的数据都会放到GitHub上(<a href="https://github.com/PytLab/MLBox" target="_blank" rel="external">https://github.com/PytLab/MLBox</a>).</p>
<p>本文中我将一步步通过MLiA的隐形眼镜处方数集构建决策树并使用Graphviz将决策树可视化。</p>
<a id="more"></a>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="决策树学习"><a href="#决策树学习" class="headerlink" title="决策树学习"></a>决策树学习</h3><p>决策树学习是根据数据的属性采用树状结构建立的一种决策模型，可以用此模型解决分类和回归问题。常见的算法包括 CART(Classification And Regression Tree), ID3, C4.5等。我们往往根据数据集来构建一棵决策树，他的一个重要任务就是为了数据中所蕴含的知识信息，并提取出一系列的规则，这些规则也就是树结构的创建过程就是机器学习的过程。</p>
<h3 id="决策树的结构"><a href="#决策树的结构" class="headerlink" title="决策树的结构"></a>决策树的结构</h3><p>以下面一个简单的用于是否买电脑预测的决策树为例子，树中的内部节点表示某个属性，节点引出的分支表示此属性的所有可能的值，叶子节点表示最终的判断结果也就是类型。</p>
<p><img src="/assets/images/blog_img/2017-07-09-机器学习算法实践-决策树/tree-structure.jpg" alt=""></p>
<p>借助可视化工具例如Graphviz，matplotlib的注解等等都可以讲我们创建的决策树模型可视化并直接被人理解，这是贝叶斯神经网络等算法没有的特性。</p>
<h3 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h3><p>决策树算法主要是指决策树进行创建中进行树分裂(划分数据集)的时候选取最优特征的算法，他的主要目的就是要选取一个特征能够将分开的数据集尽量的规整，也就是尽可能的<strong>纯</strong>. 最大的原则就是: <strong>将无序的数据变得更加有序</strong></p>
<p>这里总结下三个常用的方法:</p>
<ol>
<li>信息增益(information gain)</li>
<li>增益比率(gain ratio)</li>
<li>基尼不纯度(Gini impurity)</li>
</ol>
<h4 id="信息增益-Information-gain"><a href="#信息增益-Information-gain" class="headerlink" title="信息增益 (Information gain)"></a>信息增益 (Information gain)</h4><p>这里涉及到了信息论中的一些概念：某个事件的信息量，信息熵，信息增益等, 关于事件信息的通俗解释可以看知乎上的一个<a href="https://www.zhihu.com/question/22178202/answer/49929786" target="_blank" rel="external">回答</a></p>
<ul>
<li><p>某个事件$i$的信息量: 这个事件发生的概率的负对数<br>  $$TI = -log(P(x_{i}))$$</p>
</li>
<li><p>信息熵就是平均而言一个事件发生得到的信息量大小，也就是信息量的期望值<br>  $$ H = \sum_{i=1}^{n}H(x_{i}) = -\sum_{i=1}^{n}P(x_{i})log(P(x_{i})) $$</p>
<p>  任何一个序列都可以获取这个序列的信息熵，也就是将此序列分类后统计每个类型的概率，再用上述公式计算，使用Python实现如下:</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_shanno_entropy</span><span class="params">(self, values)</span>:</span></div><div class="line">    <span class="string">''' 根据给定列表中的值计算其Shanno Entropy</span></div><div class="line">    '''</div><div class="line">    uniq_vals = set(values)</div><div class="line">    val_nums = &#123;key: values.count(key) <span class="keyword">for</span> key <span class="keyword">in</span> uniq_vals&#125;</div><div class="line">    probs = [v/len(values) <span class="keyword">for</span> k, v <span class="keyword">in</span> val_nums.items()]</div><div class="line">    entropy = sum([-prob*log2(prob) <span class="keyword">for</span> prob <span class="keyword">in</span> probs])</div><div class="line">    <span class="keyword">return</span> entropy</div></pre></td></tr></table></figure>
</li>
<li><p>信息增益<br>  我们将一组数据集进行划分后，数据的信息熵会发生改变，我们可以通过使用信息熵的计算公式分别计算被划分的子数据集的信息熵并计算他们的平均值(期望值)来作为分割后的数据集的信息熵。新的信息熵的相比未划分数据的信息熵的减小值便是<strong>信息增益</strong>了. 这里我在最初就理解错了，于是写出的代码并不能创建正确的决策树。<br>  假设我们将数据集$D$划分成$k$份${D_{1}, D_{2}, … , D_{k}}$，则划分后的信息熵为:<br>  $$ H_{splited} = \sum_{j=1}^{k}P(D_{j})H(D_{j}) = \sum_{j=1}^{k} \frac{len(D_{j})}{len(D)} H(D_{j}) $$<br>  信息增益便是两个信息熵的插值<br>  $$ Gain_{splited} = H - H_{splited} $$</p>
<p>  在这里我主要使用信息增益来进行属性选择，具体的实现代码如下:</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_best_split_feature</span><span class="params">(self, dataset, classes)</span>:</span></div><div class="line">    <span class="string">''' 根据信息增益确定最好的划分数据的特征</span></div><div class="line"></div><div class="line">    :param dataset: 待划分的数据集</div><div class="line">    :param classes: 数据集对应的类型</div><div class="line"></div><div class="line">    :return: 划分数据的增益最大的属性索引</div><div class="line">    '''</div><div class="line">    base_entropy = self.get_shanno_entropy(classes)</div><div class="line"></div><div class="line">    feat_num = len(dataset[<span class="number">0</span>])</div><div class="line">    entropy_gains = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(feat_num):</div><div class="line">        splited_dict = self.split_dataset(dataset, classes, i)</div><div class="line">        new_entropy = sum([</div><div class="line">            len(sub_classes)/len(classes)*self.get_shanno_entropy(sub_classes)</div><div class="line">            <span class="keyword">for</span> _, (_, sub_classes) <span class="keyword">in</span> splited_dict.items()</div><div class="line">        ])</div><div class="line">        entropy_gains.append(base_entropy - new_entropy)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> entropy_gains.index(max(entropy_gains))</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="增益比率"><a href="#增益比率" class="headerlink" title="增益比率"></a>增益比率</h4><p>增益比率是信息增益方法的一种扩展，是为了克服信息增益带来的弱泛化的缺陷。因为按照信息增益选择，总是会倾向于选择分支多的属性，这样会是的每个子集的信息熵最小。例如给每个数据添加一个第一无二的id值特征，则按照这个id值进行分类是获得信息增益最大的，这样每个子集中的信息熵都为0，但是这样的分类便没有任何意义，没有任何泛化能力，类似过拟合。</p>
<p>因此我们可以通过引入一个分裂信息来找到一个更合适的衡量数据划分的标准，即增益比率。</p>
<p>分裂信息的公式表示为:<br>$$<br>SplitInfo(D) = \sum_{j=1}^{k} \frac{len(D_{j})}{len(D)} log(\frac{len(D_{j})}{len(D)})<br>$$<br>可见如果数据分的越多，分裂信息的值就会越大</p>
<p>这时候把分裂信息的值放到分母上便会中和信息增益带来的弊端。</p>
<p>$$ GianRatio = \frac{Gain}{SplitInfo} $$</p>
<p>当然SplitInfo有可能趋近于0，这个时候增益比率就会变得非常大而不可信，因此有时还需在分母上添加一个平滑函数，具体的可以参考参考部分列出的文章</p>
<h4 id="基尼不纯度-Gini-impurity"><a href="#基尼不纯度-Gini-impurity" class="headerlink" title="基尼不纯度(Gini impurity)"></a>基尼不纯度(Gini impurity)</h4><p>基尼不纯度的定义:<br>$$ I_{G}(D) = 1 - \sum_{i=1}^{m}p_{i}^{2} $$<br>其中$m$表示数据集$D$中类别的个数, $p_{i}$表示某种类型出现的概率。可见当只有一种类型的时候基尼不纯度的值为0，此时不纯度最低。</p>
<p>针对划分成k个子数据集的数据集的基尼不纯度可以通过如下式子计算:<br>$$ I_{G}^{splited}(D) = \sum_{j=1}^{k} \frac{len(D_{j})}{len(D)}I_{G}(D))$$</p>
<p>由此我们可以根据不纯度的变化来选取最有的树分裂属性</p>
<p>$$ \Delta I_{G} = I_{G} - I_{G}^{splited} $$</p>
<h3 id="树分裂"><a href="#树分裂" class="headerlink" title="树分裂"></a>树分裂</h3><p>有了选取最佳分裂属性的算法，下面我们就需要根据选择的属性来将树进一步的分裂。所谓树分裂只不过是根据选择的属性将数据集划分，然后在总划分出来的数据集中再次调用选取属性的方法选取子数据集的中属性。实现的最好方式就是递归了.</p>
<p>关于用什么数据结构来表示决策树，在Python中可以使用字典很方便的表示决策树的嵌套，一个树的根节点便是属性，属性对应的值又是一个新的字典，其中key为属性的可能值，value为新的子树。</p>
<p>下面是我使用Python实现的根据数据集创建决策树：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(self, dataset, classes, feat_names)</span>:</span></div><div class="line">    <span class="string">''' 根据当前数据集递归创建决策树</span></div><div class="line"></div><div class="line">    :param dataset: 数据集</div><div class="line">    :param feat_names: 数据集中数据相应的特征名称</div><div class="line">    :param classes: 数据集中数据相应的类型</div><div class="line"></div><div class="line">    :param tree: 以字典形式返回决策树</div><div class="line">    '''</div><div class="line">    <span class="comment"># 如果数据集中只有一种类型停止树分裂</span></div><div class="line">    <span class="keyword">if</span> len(set(classes)) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> classes[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="comment"># 如果遍历完所有特征，返回比例最多的类型</span></div><div class="line">    <span class="keyword">if</span> len(feat_names) == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> get_majority(classes)</div><div class="line"></div><div class="line">    <span class="comment"># 分裂创建新的子树</span></div><div class="line">    tree = &#123;&#125;</div><div class="line">    best_feat_idx = self.choose_best_split_feature(dataset, classes)</div><div class="line">    feature = feat_names[best_feat_idx]</div><div class="line">    tree[feature] = &#123;&#125;</div><div class="line"></div><div class="line">    <span class="comment"># 创建用于递归创建子树的子数据集</span></div><div class="line">    sub_feat_names = feat_names[:]</div><div class="line">    sub_feat_names.pop(best_feat_idx)</div><div class="line"></div><div class="line">    splited_dict = self.split_dataset(dataset, classes, best_feat_idx)</div><div class="line">    <span class="keyword">for</span> feat_val, (sub_dataset, sub_classes) <span class="keyword">in</span> splited_dict.items():</div><div class="line">        tree[feature][feat_val] = self.create_tree(sub_dataset,</div><div class="line">                                                   sub_classes,</div><div class="line">                                                   sub_feat_names)</div><div class="line">    self.tree = tree</div><div class="line">    self.feat_names = feat_names</div><div class="line"></div><div class="line">    <span class="keyword">return</span> tree</div></pre></td></tr></table></figure></p>
<p>树分裂的终止条件有两个</p>
<ul>
<li><p>一个是遍历完所有的属性<br>  可以看到，在进行树分裂的时候，我们的数据集中的数据向量的长度是不断缩短的，当缩短到0时，说明数据集已经将所有的属性用尽，便也分裂不下去了, 这时我们选取最终子数据集中的众数作为最终的分类结果放到叶子节点上.</p>
</li>
<li><p>另一个是新划分的数据集中只有一个类型。<br> 若某个节点所指向的数据集都是同一种类型，那自然没有必要在分裂下去了即使属性还没有遍历完.</p>
</li>
</ul>
<h3 id="构建一棵决策树"><a href="#构建一棵决策树" class="headerlink" title="构建一棵决策树"></a>构建一棵决策树</h3><p>这我用了一下MLiA书上附带的隐形眼镜的数据来生成一棵决策树，数据中包含了患者眼部状况以及医生推荐的隐形眼镜类型.</p>
<p>首先先导入数据并将数据特征同类型分开作为训练数据用于生成决策树<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> trees <span class="keyword">import</span> DecisionTreeClassifier</div><div class="line"></div><div class="line">lense_labels = [<span class="string">'age'</span>, <span class="string">'prescript'</span>, <span class="string">'astigmatic'</span>, <span class="string">'tearRate'</span>]</div><div class="line">X = []</div><div class="line">Y = []</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'lenses.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">        comps = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">        X.append(comps[: <span class="number">-1</span>])</div><div class="line">        Y.append(comps[<span class="number">-1</span>])</div></pre></td></tr></table></figure></p>
<p>生成决策树:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">clf = DecisionTreeClassifier()</div><div class="line">clf.create_tree(X, Y, lense_labels)</div></pre></td></tr></table></figure>
<p>查看生成的决策树:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">In [<span class="number">2</span>]: clf.tree</div><div class="line">Out[<span class="number">2</span>]:</div><div class="line">&#123;<span class="string">'tearRate'</span>: &#123;<span class="string">'normal'</span>: &#123;<span class="string">'astigmatic'</span>: &#123;<span class="string">'no'</span>: &#123;<span class="string">'age'</span>: &#123;<span class="string">'pre'</span>: <span class="string">'soft'</span>,</div><div class="line">      <span class="string">'presbyopic'</span>: &#123;<span class="string">'prescript'</span>: &#123;<span class="string">'hyper'</span>: <span class="string">'soft'</span>, <span class="string">'myope'</span>: <span class="string">'no lenses'</span>&#125;&#125;,</div><div class="line">            <span class="string">'young'</span>: <span class="string">'soft'</span>&#125;&#125;,</div><div class="line">    <span class="string">'yes'</span>: &#123;<span class="string">'prescript'</span>: &#123;<span class="string">'hyper'</span>: &#123;<span class="string">'age'</span>: &#123;<span class="string">'pre'</span>: <span class="string">'no lenses'</span>,</div><div class="line">                <span class="string">'presbyopic'</span>: <span class="string">'no lenses'</span>,</div><div class="line">                        <span class="string">'young'</span>: <span class="string">'hard'</span>&#125;&#125;,</div><div class="line">          <span class="string">'myope'</span>: <span class="string">'hard'</span>&#125;&#125;&#125;&#125;,</div><div class="line">  <span class="string">'reduced'</span>: <span class="string">'no lenses'</span>&#125;&#125;</div></pre></td></tr></table></figure>
<h3 id="可视化决策树"><a href="#可视化决策树" class="headerlink" title="可视化决策树"></a>可视化决策树</h3><p>直接通过嵌套字典表示决策树对人来说不好理解，我们需要借助可视化工具可视化树结构，这里我将使用Graphviz来可视化树结构。为此实现了讲字典表示的树生成Graphviz Dot文件内容的函数，大致思想就是递归获取整棵树的所有节点和连接节点的边然后将这些节点和边生成Dot格式的字符串写入文件中并绘图。</p>
<p>递归获取树的节点和边，其中使用了uuid给每个节点添加了id属性以便将相同属性的节点区分开.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_nodes_edges</span><span class="params">(self, tree=None, root_node=None)</span>:</span></div><div class="line">    <span class="string">''' 返回树中所有节点和边</span></div><div class="line">    '''</div><div class="line">    Node = namedtuple(<span class="string">'Node'</span>, [<span class="string">'id'</span>, <span class="string">'label'</span>])</div><div class="line">    Edge = namedtuple(<span class="string">'Edge'</span>, [<span class="string">'start'</span>, <span class="string">'end'</span>, <span class="string">'label'</span>])</div><div class="line"></div><div class="line">    <span class="keyword">if</span> tree <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        tree = self.tree</div><div class="line"></div><div class="line">    <span class="keyword">if</span> type(tree) <span class="keyword">is</span> <span class="keyword">not</span> dict:</div><div class="line">        <span class="keyword">return</span> [], []</div><div class="line"></div><div class="line">    nodes, edges = [], []</div><div class="line"></div><div class="line">    <span class="keyword">if</span> root_node <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        label = list(tree.keys())[<span class="number">0</span>]</div><div class="line">        root_node = Node._make([uuid.uuid4(), label])</div><div class="line">        nodes.append(root_node)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> edge_label, sub_tree <span class="keyword">in</span> tree[root_node.label].items():</div><div class="line">        node_label = list(sub_tree.keys())[<span class="number">0</span>] <span class="keyword">if</span> type(sub_tree) <span class="keyword">is</span> dict <span class="keyword">else</span> sub_tree</div><div class="line">        sub_node = Node._make([uuid.uuid4(), node_label])</div><div class="line">        nodes.append(sub_node)</div><div class="line"></div><div class="line">        edge = Edge._make([root_node, sub_node, edge_label])</div><div class="line">        edges.append(edge)</div><div class="line"></div><div class="line">        sub_nodes, sub_edges = self.get_nodes_edges(sub_tree, root_node=sub_node)</div><div class="line">        nodes.extend(sub_nodes)</div><div class="line">        edges.extend(sub_edges)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> nodes, edges</div></pre></td></tr></table></figure>
<p>生成dot文件内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dotify</span><span class="params">(self, tree=None)</span>:</span></div><div class="line">    <span class="string">''' 获取树的Graphviz Dot文件的内容</span></div><div class="line">    '''</div><div class="line">    <span class="keyword">if</span> tree <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        tree = self.tree</div><div class="line"></div><div class="line">    content = <span class="string">'digraph decision_tree &#123;\n'</span></div><div class="line">    nodes, edges = self.get_nodes_edges(tree)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</div><div class="line">        content += <span class="string">'    "&#123;&#125;" [label="&#123;&#125;"];\n'</span>.format(node.id, node.label)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</div><div class="line">        start, label, end = edge.start, edge.label, edge.end</div><div class="line">        content += <span class="string">'    "&#123;&#125;" -&gt; "&#123;&#125;" [label="&#123;&#125;"];\n'</span>.format(start.id, end.id, label)</div><div class="line">    content += <span class="string">'&#125;'</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> content</div></pre></td></tr></table></figure>
<p>这样我们便可以使用Graphviz将决策树绘制出来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> open(<span class="string">'lenses.dot'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">    dot = clf.tree.dotify()</div><div class="line">    f.write(dot)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dot -Tgif lenses.dot -o lenses.gif</div></pre></td></tr></table></figure>
<p>效果如下:<br><img src="/assets/images/blog_img/2017-07-09-机器学习算法实践-决策树/lenses.gif" alt=""></p>
<h3 id="使用生成的决策树进行分类"><a href="#使用生成的决策树进行分类" class="headerlink" title="使用生成的决策树进行分类"></a>使用生成的决策树进行分类</h3><p>对未知数据进行预测，主要是根据树中的节点递归的找到叶子节点即可。z这里可以通过为递归进行优化，代码实现如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, data_vect, feat_names=None, tree=None)</span>:</span></div><div class="line">    <span class="string">''' 根据构建的决策树对数据进行分类</span></div><div class="line">    '''</div><div class="line">    <span class="keyword">if</span> tree <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        tree = self.tree</div><div class="line"></div><div class="line">    <span class="keyword">if</span> feat_names <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        feat_names = self.feat_names</div><div class="line"></div><div class="line">    <span class="comment"># Recursive base case.</span></div><div class="line">    <span class="keyword">if</span> type(tree) <span class="keyword">is</span> <span class="keyword">not</span> dict:</div><div class="line">        <span class="keyword">return</span> tree</div><div class="line"></div><div class="line">    feature = list(tree.keys())[<span class="number">0</span>]</div><div class="line">    value = data_vect[feat_names.index(feature)]</div><div class="line">    sub_tree = tree[feature][value]</div><div class="line"></div><div class="line">    <span class="keyword">return</span> self.classify(feat_names, data_vect, sub_tree)</div></pre></td></tr></table></figure></p>
<h3 id="决策树的存储"><a href="#决策树的存储" class="headerlink" title="决策树的存储"></a>决策树的存储</h3><p>通过字典表示决策树，这样我们可以通过内置的pickle或者json模块将其存储到硬盘上，同时也可以从硬盘中读取树结构，这样在数据集很大的时候可以节省构建决策树的时间.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dump_tree</span><span class="params">(self, filename, tree=None)</span>:</span></div><div class="line">    <span class="string">''' 存储决策树</span></div><div class="line">    '''</div><div class="line">    <span class="keyword">if</span> tree <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        tree = self.tree</div><div class="line"></div><div class="line">    <span class="keyword">with</span> open(filename, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">        pickle.dump(tree, f)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_tree</span><span class="params">(self, filename)</span>:</span></div><div class="line">    <span class="string">''' 加载树结构</span></div><div class="line">    '''</div><div class="line">    <span class="keyword">with</span> open(filename, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">        tree = pickle.load(f)</div><div class="line">        self.tree = tree</div><div class="line">    <span class="keyword">return</span> tree</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文一步步实现了决策树的实现, 其中使用了ID3算法确定最佳划分属性，并通过Graphviz可视化了构建的决策树。本文相关的代码链接: <a href="https://github.com/PytLab/MLBox/tree/master/decision_tree" target="_blank" rel="external">https://github.com/PytLab/MLBox/tree/master/decision_tree</a></p>
	  
	</div>

    
	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
		
          <li class="prev disabled"><a><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
        

        <li><a href="/"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2017/07/04/KinLab-基于Flask-Bootstrap实现微观动力学计算的web应用/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>
    
	
    <!-- bdshare -->
    
        
    <div class="bdsharebuttonbox">
        <a href="#" class="bds_more" data-cmd="more"></a>
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
        <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
        <a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
        <a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
        <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
    </div>
    <script>
        window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};
        with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>


        

    

	<!-- comment -->
    
<section id="comment">
  <h2 class="title">Comments</h2>

  
  	 <div id="disqus_thread">
     <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  	 </div>
  
</section>

	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2017-07-09 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/学习小结/">学习小结<span class="badge">82</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/python/">python<span class="badge">46</span></a></li> <li><a href="/tags/MachineLearning/">MachineLearning<span class="badge">1</span></a></li> <li><a href="/tags/DecisionTree/">DecisionTree<span class="badge">1</span></a></li>

    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	   <a data-toggle="collapse" data-target="#toc"><i class="fa fa-bars"></i></a>
	   <div id="toc" class="toc collapse in">
			<ol class="toc-article"><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#前言"><span class="toc-article-text">前言</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#正文"><span class="toc-article-text">正文</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#决策树学习"><span class="toc-article-text">决策树学习</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#决策树的结构"><span class="toc-article-text">决策树的结构</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#决策树算法"><span class="toc-article-text">决策树算法</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-4"><a class="toc-article-link" href="#信息增益-Information-gain"><span class="toc-article-text">信息增益 (Information gain)</span></a></li><li class="toc-article-item toc-article-level-4"><a class="toc-article-link" href="#增益比率"><span class="toc-article-text">增益比率</span></a></li><li class="toc-article-item toc-article-level-4"><a class="toc-article-link" href="#基尼不纯度-Gini-impurity"><span class="toc-article-text">基尼不纯度(Gini impurity)</span></a></li></ol></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#树分裂"><span class="toc-article-text">树分裂</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#构建一棵决策树"><span class="toc-article-text">构建一棵决策树</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#可视化决策树"><span class="toc-article-text">可视化决策树</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#使用生成的决策树进行分类"><span class="toc-article-text">使用生成的决策树进行分类</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#决策树的存储"><span class="toc-article-text">决策树的存储</span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#总结"><span class="toc-article-text">总结</span></a></li></ol>
		</div>
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->

<script type="text/javascript">
var disqus_shortname = 'pytlab';
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  
  &copy; copyright 2017 by <a href="http://pytlab.github.io"> PytLab </a>
  
      &nbsp; <a href="http://github.com/PytLab/hexo-theme-freemind/">Theme</a> by <a href="http://pytlab.github.io/">PytLab</a> based on <a href="https://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



</body>
   </html>
