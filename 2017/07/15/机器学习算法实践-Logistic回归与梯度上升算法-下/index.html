<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>机器学习算法实践-Logistic回归与梯度上升算法(下) | PytLab</title>
  <meta name="author" content="PytLab">
  
  <meta name="description" content="Personal Blog of ShaoZhengjiang">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="机器学习算法实践-Logistic回归与梯度上升算法(下)"/>
  <meta property="og:site_name" content="PytLab"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <link rel="alternative" href="/true" title="PytLab" type="application/atom+xml">
  
  
    <link href="/assets/images/favicon/icon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/bootstrap.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-73223373-1', 'auto');
  ga('send', 'pageview');
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

 <body>  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav id="main-nav" class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/"></a>
      <div class="collapse navbar-collapse nav-menu">
		    <ul class="nav navbar-nav">
		      

          <!-- Categories -->
          
          <li>
            <a href="/" title="PytLab's Home" style="font-weight: normal; font-family: Calibri,Arial; font-size: 18px">
              <i class="fa fa-bank"></i>Home
            </a>
          </li>
          
		      

          <!-- Categories -->
          
          <!-- Archives -->
          <li class="dropdown">
            <a href="/archives" class="dropdown-toggle" data-toggle="dropdown" title="All the articles." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
            <i class="fa fa-archive"></i>Archives
            <b class="caret"></b>   
            </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/archives" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Archives</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/2017/07/15/机器学习算法实践-Logistic回归与梯度上升算法-下/" style="font-size: 15px; font-family: 微软雅黑">机器学习算法实践-Logistic回归与梯度上升算法(下)<span></span></a></li>
              
              <li><a href="/2017/07/13/机器学习算法实践-Logistic回归与梯度上升算法-上/" style="font-size: 15px; font-family: 微软雅黑">机器学习算法实践-Logistic回归与梯度上升算法(上)<span></span></a></li>
              
              <li><a href="/2017/07/11/机器学习实践-朴素贝叶斯-Naive-Bayes/" style="font-size: 15px; font-family: 微软雅黑">机器学习算法实践-朴素贝叶斯(Naive Bayes)<span></span></a></li>
              
              <li><a href="/2017/07/09/机器学习算法实践-决策树/" style="font-size: 15px; font-family: 微软雅黑">机器学习算法实践-决策树(Decision Tree)<span></span></a></li>
              
              <li><a href="/2017/07/04/KinLab-基于Flask-Bootstrap实现微观动力学计算的web应用/" style="font-size: 15px; font-family: 微软雅黑">KinLab - 基于Flask+Bootstrap实...<span></span></a></li>
              
              <li><a href="/2017/06/18/实现一个Bootstrap的JS插件/" style="font-size: 15px; font-family: 微软雅黑">编写Bootstrap插件的步骤<span></span></a></li>
              
              <li><a href="/2017/06/03/算法分析中的渐进记号总结/" style="font-size: 15px; font-family: 微软雅黑">算法分析中的渐近记号总结<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
          </li>

          
		      

          <!-- Categories -->
          
		      <li class="dropdown">
            <a href="/categories" class="dropdown-toggle" data-toggle="dropdown" title="All the categories." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
		    	  <i class="fa fa-folder"></i>Categories
            <b class="caret"></b>   
		    	  </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/categories" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Categories</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/categories/学习小结/" style="font-size: 15px; font-family: 微软雅黑">学习小结<span></span></a></li>
              
              <li><a href="/categories/学术/" style="font-size: 15px; font-family: 微软雅黑">学术<span></span></a></li>
              
              <li><a href="/categories/代码作品/" style="font-size: 15px; font-family: 微软雅黑">代码作品<span></span></a></li>
              
              <li><a href="/categories/教程/" style="font-size: 15px; font-family: 微软雅黑">教程<span></span></a></li>
              
              <li><a href="/categories/我的日常/" style="font-size: 15px; font-family: 微软雅黑">我的日常<span></span></a></li>
              
              <li><a href="/categories/随笔/" style="font-size: 15px; font-family: 微软雅黑">随笔<span></span></a></li>
              
              <li><a href="/categories/工具应用/" style="font-size: 15px; font-family: 微软雅黑">工具应用<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
		      </li>

          
		      

          <!-- Categories -->
          
          <!-- Tags -->
          <li class="dropdown">
            <a href="/tags" class="dropdown-toggle" data-toggle="dropdown" title="All the tags." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
            <i class="fa fa-tags"></i>Tags
            <b class="caret"></b>   
            </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/tags" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Tags</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/tags/Cpp/" style="font-size: 15px; font-family: 微软雅黑">Cpp<span></span></a></li>
              
              <li><a href="/tags/python/" style="font-size: 15px; font-family: 微软雅黑">python<span></span></a></li>
              
              <li><a href="/tags/catalysis/" style="font-size: 15px; font-family: 微软雅黑">catalysis<span></span></a></li>
              
              <li><a href="/tags/C/" style="font-size: 15px; font-family: 微软雅黑">C<span></span></a></li>
              
              <li><a href="/tags/chemistry/" style="font-size: 15px; font-family: 微软雅黑">chemistry<span></span></a></li>
              
              <li><a href="/tags/Parallel-Computing/" style="font-size: 15px; font-family: 微软雅黑">Parallel Computing<span></span></a></li>
              
              <li><a href="/tags/学术/" style="font-size: 15px; font-family: 微软雅黑">学术<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
          </li>
          
          
		      

          <!-- Categories -->
          
          <li>
            <a href="/about" title="About me." style="font-weight: normal; font-family: Calibri,Arial; font-size: 18px">
              <i class="fa fa-user"></i>About
            </a>
          </li>
          
		      
		    </ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">		
			<h1> 机器学习算法实践-Logistic回归与梯度上升算法(下)</h1>
		</div>		
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上篇主要总结了Logistic回归模型建立的理论基础，主要包含模型似然函数的建立以及梯度上升算法的优化推导。本文在上文的基础上使用Python一步步实现一个Logistic回归分类器，并分别使用梯度上升和随机梯度上升算法实现，对二维数据点分类进行可视化，最后使用之前使用过的<a href="http://www.esp.uem.es/jmgomez/smsspamcorpus/" target="_blank" rel="external">SMS垃圾短信语料库</a>中的短信数据进行模型训练并对短信数据进行分类。</p>
<a id="more"></a>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><p>从文件中读取特征以及类别标签用于优化模型参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(filename)</span>:</span></div><div class="line">    dataset, labels = [], []</div><div class="line">    <span class="keyword">with</span> open(filename, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">            splited_line = [float(i) <span class="keyword">for</span> i <span class="keyword">in</span> line.strip().split(<span class="string">'\t'</span>)]</div><div class="line">            data, label = [<span class="number">1.0</span>] + splited_line[: <span class="number">-1</span>], splited_line[<span class="number">-1</span>]</div><div class="line">            dataset.append(data)</div><div class="line">            labels.append(label)</div><div class="line">    dataset = np.array(dataset)</div><div class="line">    labels = np.array(labels)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> dataset, labels</div></pre></td></tr></table></figure>
<h3 id="使用梯度上升算法"><a href="#使用梯度上升算法" class="headerlink" title="使用梯度上升算法"></a>使用梯度上升算法</h3><p>上文对Logistic回归模型使用梯度上升算法优化参数进行了理论介绍，这里就最先使用梯度上升算法来构建一个分类器.</p>
<p>首先我们是Sigmoid函数:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="string">''' Sigmoid 阶跃函数</span></div><div class="line">    '''</div><div class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span> + np.exp(-x))</div></pre></td></tr></table></figure></p>
<p>然后是梯度上升算法的实现:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_ascent</span><span class="params">(self, dataset, labels, max_iter=<span class="number">10000</span>)</span>:</span></div><div class="line">    <span class="string">''' 使用梯度上升优化Logistic回归模型参数</span></div><div class="line"></div><div class="line">    :param dataset: 数据特征矩阵</div><div class="line">    :type dataset: MxN numpy matrix</div><div class="line"></div><div class="line">    :param labels: 数据集对应的类型向量</div><div class="line">    :type labels: Nx1 numpy matrix</div><div class="line">    '''</div><div class="line">    dataset = np.matrix(dataset)</div><div class="line">    vlabels = np.matrix(labels).reshape(<span class="number">-1</span>, <span class="number">1</span>)</div><div class="line">    m, n = dataset.shape</div><div class="line">    w = np.ones((n, <span class="number">1</span>))</div><div class="line">    alpha = <span class="number">0.001</span></div><div class="line">    ws = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_iter):</div><div class="line">        error = vlabels - self.sigmoid(dataset*w)</div><div class="line">        w += alpha*dataset.T*error</div><div class="line">        ws.append(w.reshape(<span class="number">1</span>, <span class="number">-1</span>).tolist()[<span class="number">0</span>])</div><div class="line"></div><div class="line">    self.w = w</div><div class="line"></div><div class="line">    <span class="keyword">return</span> w, np.array(ws)</div></pre></td></tr></table></figure></p>
<p>在这里的数据操作都转换成Numpy矩阵的操作，主要是方便处理避免Python循环处理。同时每次梯度上升迭代过程中都把自变量，也就是Logistic模型参数进行收集，方便最后查看参数收敛情况。</p>
<p>关于梯度上升算法中，我们每次沿着梯度方向移动的步长 $\alpha$ 都设的固定距离为0.001，并没有做一维搜索。</p>
<h3 id="可视化决策边界"><a href="#可视化决策边界" class="headerlink" title="可视化决策边界"></a>可视化决策边界</h3><p>Sigmoid函数的特点就是通过0点来进行分类，$\overline{x}^{T} \centerdot \overline{\omega}$ 的值小于0为一类，大于0位另外一类，因此我们可以通过 $\overline{x}^{T} \centerdot \overline{\omega} = 0$ 来获取分界线或者超平面。在二维平面里，我们可以通过求解 $w_{0}x_{0} + w_{1}x_{0}$(其中 $x_{0} = 1$) 并绘制直线来可视化决策边界。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">snapshot</span><span class="params">(w, dataset, labels, pic_name)</span>:</span></div><div class="line">    <span class="string">''' 绘制类型分割线图</span></div><div class="line">    '''</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'./snapshots'</span>):</div><div class="line">        os.mkdir(<span class="string">'./snapshots'</span>)</div><div class="line"></div><div class="line">    fig = plt.figure()</div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>)</div><div class="line"></div><div class="line">    pts = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> zip(dataset.tolist(), labels.tolist()):</div><div class="line">        pts.setdefault(label, [data]).append(data)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> label, data <span class="keyword">in</span> pts.items():</div><div class="line">        data = np.array(data)</div><div class="line">        plt.scatter(data[:, <span class="number">1</span>], data[:, <span class="number">2</span>], label=label, alpha=<span class="number">0.5</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 分割线绘制</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_y</span><span class="params">(x, w)</span>:</span></div><div class="line">        w0, w1, w2 = w</div><div class="line">        <span class="keyword">return</span> (-w0 - w1*x)/w2</div><div class="line"></div><div class="line">    x = [<span class="number">-4.0</span>, <span class="number">3.0</span>]</div><div class="line">    y = [get_y(i, w) <span class="keyword">for</span> i <span class="keyword">in</span> x]</div><div class="line"></div><div class="line">    plt.plot(x, y, linewidth=<span class="number">2</span>, color=<span class="string">'#FB4A42'</span>)</div><div class="line"></div><div class="line">    pic_name = <span class="string">'./snapshots/&#123;&#125;'</span>.format(pic_name)</div><div class="line">    fig.savefig(pic_name)</div><div class="line">    plt.close(fig)</div></pre></td></tr></table></figure>
<p>好了，优化算法和可视化代码都具备了，我们便可以拟合我们的数据了，这里使用两种类型的二维数据点来训练模型, 数据见<a href="https://github.com/PytLab/MLBox/blob/master/logistic_regression/testSet.txt" target="_blank" rel="external">https://github.com/PytLab/MLBox/blob/master/logistic_regression/testSet.txt</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> <span class="string">'__main__'</span> == __name__:</div><div class="line">    clf = LogisticRegressionClassifier()</div><div class="line">    dataset, labels = load_data(<span class="string">'testSet.txt'</span>)</div><div class="line">    w, ws = clf.gradient_ascent(dataset, labels, max_iter=<span class="number">50000</span>)</div><div class="line">    m, n = ws.shape</div><div class="line"></div><div class="line">    <span class="comment"># 绘制分割线</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</div><div class="line">        <span class="keyword">if</span> i % (<span class="number">30</span>) == <span class="number">0</span>:</div><div class="line">            print(<span class="string">'&#123;&#125;.png saved'</span>.format(i))</div><div class="line">            snapshot(ws[i].tolist(), dataset, labels, <span class="string">'&#123;&#125;.png'</span>.format(i))</div><div class="line"></div><div class="line">    fig = plt.figure()</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">        label = <span class="string">'w&#123;&#125;'</span>.format(i)</div><div class="line">        ax = fig.add_subplot(n, <span class="number">1</span>, i+<span class="number">1</span>)</div><div class="line">        ax.plot(ws[:, i], label=label)</div><div class="line">        ax.legend()</div><div class="line"></div><div class="line">    fig.savefig(<span class="string">'w_traj.png'</span>)</div></pre></td></tr></table></figure>
<p>通过将迭代过程中的权重参数输出，我们可以绘制决策边界的变化，看到参数的优化过程:</p>
<p><img src="/assets/images/blog_img/2017-07-15-机器学习算法实践-Logistic回归与梯度上升算法-下/grad_ascent_animation.gif" alt=""></p>
<p>下面我们可视化一下模型参数在梯度上升过程中的收敛情况，我们总共迭代了50000步：</p>
<p><img src="/assets/images/blog_img/2017-07-15-机器学习算法实践-Logistic回归与梯度上升算法-下/grad_ascent_params.png" alt=""></p>
<h3 id="使用随机随机梯度上升算法"><a href="#使用随机随机梯度上升算法" class="headerlink" title="使用随机随机梯度上升算法"></a>使用随机随机梯度上升算法</h3><p>从求目标函数梯度的公式<br>$$<br>\nabla ln\mathcal{L}(\overline{\omega}) = \overline{x} \centerdot (\overline{y} - \overline{\pi(\overline{x})}) = \overline{x} \centerdot \overline{error}<br>$$<br>和实现代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">error = vlabels - self.sigmoid(dataset*w)</div><div class="line">w += alpha*dataset.T*error</div></pre></td></tr></table></figure></p>
<p>中我们可以看到，在使用梯度上升算法优化的时候每次迭代都需要使用所有的训练数据乘上误差向量，如果样本只有几百个那还好，如果有数十亿样本，那这个矩阵乘法将会非常的大，于是我们可以考虑使用随机梯度上升来更新 $\omega$, 所谓随机梯度就是指更新 $\omega$ 的时候不需要用所有的数据矩阵和误差矩阵乘积来更新，而是使用样本中随机选出的一个数据点来计算梯度并更新。这样可以在新的样本到来时对分类器进行<strong>增量式更新</strong>，因而随机梯度算法是一个<strong>在线学习</strong>算法, 之前的梯度上升算法是一次性处理所有样本数据被称作是<strong>批处理</strong>。</p>
<p>下面我们就重新写一个通过随机梯度上升算法优化的Logistic回归分类器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> logreg_grad_ascent <span class="keyword">import</span> LogisticRegressionClassifier <span class="keyword">as</span> BaseClassifer</div><div class="line"><span class="keyword">from</span> logreg_grad_ascent <span class="keyword">import</span> load_data, snapshot</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegressionClassifier</span><span class="params">(BaseClassifer)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stoch_gradient_ascent</span><span class="params">(self, dataset, labels, max_iter=<span class="number">150</span>)</span>:</span></div><div class="line">        <span class="string">''' 使用随机梯度上升算法优化Logistic回归模型参数</span></div><div class="line">        '''</div><div class="line">        dataset = np.matrix(dataset)</div><div class="line">        m, n = dataset.shape</div><div class="line">        w = np.matrix(np.ones((n, <span class="number">1</span>)))</div><div class="line">        ws = []</div><div class="line"></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(max_iter):</div><div class="line">            data_indices = list(range(m))</div><div class="line">            random.shuffle(data_indices)</div><div class="line">            <span class="keyword">for</span> j, idx <span class="keyword">in</span> enumerate(data_indices):</div><div class="line">                data, label = dataset[idx], labels[idx]</div><div class="line">                error = label - self.sigmoid((data*w).tolist()[<span class="number">0</span>][<span class="number">0</span>])</div><div class="line">                alpha = <span class="number">4</span>/(<span class="number">1</span> + j + i) + <span class="number">0.01</span></div><div class="line">                w += alpha*data.T*error</div><div class="line">                ws.append(w.T.tolist()[<span class="number">0</span>])</div><div class="line"></div><div class="line">        self.w = w</div><div class="line"></div><div class="line">        <span class="keyword">return</span> w, np.array(ws)</div></pre></td></tr></table></figure></p>
<p>我们写一个继承与刚才实现的分类器的派生类，并实现随机梯度算法，这里沿着梯度方向的步长随着迭代会逐渐减小来减弱参数的博定。</p>
<p>我们同样来可视化决策边界和参数的收敛曲线来看看随机梯度下降法对模型的优化过程:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> <span class="string">'__main__'</span> == __name__:</div><div class="line">    clf = LogisticRegressionClassifier()</div><div class="line">    dataset, labels = load_data(<span class="string">'testSet.txt'</span>)</div><div class="line">    w, ws = clf.stoch_gradient_ascent(dataset, labels, max_iter=<span class="number">500</span>)</div><div class="line">    m, n = ws.shape</div><div class="line"></div><div class="line">    <span class="comment"># 绘制分割线</span></div><div class="line">    <span class="keyword">for</span> i, w <span class="keyword">in</span> enumerate(ws):</div><div class="line">        <span class="keyword">if</span> i % (m//<span class="number">10</span>) == <span class="number">0</span>:</div><div class="line">            print(<span class="string">'&#123;&#125;.png saved'</span>.format(i))</div><div class="line">            snapshot(w.tolist(), dataset, labels, <span class="string">'&#123;&#125;.png'</span>.format(i))</div><div class="line"></div><div class="line">    fig = plt.figure()</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">        label = <span class="string">'w&#123;&#125;'</span>.format(i)</div><div class="line">        ax = fig.add_subplot(n, <span class="number">1</span>, i+<span class="number">1</span>)</div><div class="line">        ax.plot(ws[:, i], label=label)</div><div class="line">        ax.legend()</div><div class="line"></div><div class="line">    fig.savefig(<span class="string">'stoch_grad_ascent_params.png'</span>)</div></pre></td></tr></table></figure></p>
<p>决策线变化:<br><img src="/assets/images/blog_img/2017-07-15-机器学习算法实践-Logistic回归与梯度上升算法-下/stoch_grad_ascent_animation.gif" alt=""></p>
<p>参数收敛曲线:<br><img src="/assets/images/blog_img/2017-07-15-机器学习算法实践-Logistic回归与梯度上升算法-下/stoch_grad_ascent_params.png" alt=""></p>
<h3 id="使用Logistic回归分类器分类短信"><a href="#使用Logistic回归分类器分类短信" class="headerlink" title="使用Logistic回归分类器分类短信"></a>使用Logistic回归分类器分类短信</h3><p>这里我还是使用了前两篇决策树和贝叶斯分类器使用的垃圾短信数据集来训练Logistic回归分类器，这时候对于Logistic分类器的参数可能会比较多，我们使用随机梯度上升算法来优化参数，相对于贝叶斯分类器，基于随机梯度上升算法的Logistic回归分类器对于维数较高的的数据向量和数量较大的数据集的训练速度还是有待改善的，我们同样使用留存调查验证的方式来训练和测试模型，测试了三次Logistic回归模型对于垃圾短信的识别错误率分别为: 0.0833, 0.038, 0.038.</p>
<p><img src="/assets/images/blog_img/2017-07-15-机器学习算法实践-Logistic回归与梯度上升算法-下/error-rates.png" alt=""></p>
<p>平均错误率为5.3%。可见我们的Logistic回归分类器也能较好的对垃圾短信文本进行识别。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文总结了Logistic回归和相关的优化算法(梯度上升以及随机梯度上升)的理论和代码实现，并对实现的模型进行了训练和测试。</p>
	  
	</div>

    
	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
		
          <li class="prev disabled"><a><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
        

        <li><a href="/"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2017/07/13/机器学习算法实践-Logistic回归与梯度上升算法-上/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>
    
	
    <!-- bdshare -->
    
        
    <div class="bdsharebuttonbox">
        <a href="#" class="bds_more" data-cmd="more"></a>
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
        <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
        <a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
        <a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
        <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
    </div>
    <script>
        window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};
        with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>


        

    

	<!-- comment -->
    
<section id="comment">
  <h2 class="title">Comments</h2>

  
  	 <div id="disqus_thread">
     <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  	 </div>
  
</section>

	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2017-07-15 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/学习小结/">学习小结<span class="badge">85</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/python/">python<span class="badge">49</span></a></li> <li><a href="/tags/MachineLearning/">MachineLearning<span class="badge">4</span></a></li> <li><a href="/tags/LogisticRegression/">LogisticRegression<span class="badge">2</span></a></li> <li><a href="/tags/Optimization/">Optimization<span class="badge">2</span></a></li> <li><a href="/tags/GradientAscent/">GradientAscent<span class="badge">2</span></a></li> <li><a href="/tags/StochasticGradientAscent/">StochasticGradientAscent<span class="badge">1</span></a></li>

    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	   <a data-toggle="collapse" data-target="#toc"><i class="fa fa-bars"></i></a>
	   <div id="toc" class="toc collapse in">
			<ol class="toc-article"><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#前言"><span class="toc-article-text">前言</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#正文"><span class="toc-article-text">正文</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#加载数据"><span class="toc-article-text">加载数据</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#使用梯度上升算法"><span class="toc-article-text">使用梯度上升算法</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#可视化决策边界"><span class="toc-article-text">可视化决策边界</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#使用随机随机梯度上升算法"><span class="toc-article-text">使用随机随机梯度上升算法</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#使用Logistic回归分类器分类短信"><span class="toc-article-text">使用Logistic回归分类器分类短信</span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#总结"><span class="toc-article-text">总结</span></a></li></ol>
		</div>
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->

<script type="text/javascript">
var disqus_shortname = 'pytlab';
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  
  &copy; copyright 2017 by <a href="http://pytlab.github.io"> PytLab </a>
  
      &nbsp; <a href="http://github.com/PytLab/hexo-theme-freemind/">Theme</a> by <a href="http://pytlab.github.io/">PytLab</a> based on <a href="https://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



</body>
   </html>
