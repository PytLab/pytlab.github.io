<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>实现属于自己的TensorFlow(一) - 计算图与前向传播 | PytLab</title>
  <meta name="author" content="PytLab">
  
  <meta name="description" content="Personal Blog of ShaoZhengjiang">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="实现属于自己的TensorFlow(一) - 计算图与前向传播"/>
  <meta property="og:site_name" content="PytLab"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <link rel="alternative" href="/true" title="PytLab" type="application/atom+xml">
  
  
    <link href="/assets/images/favicon/icon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/bootstrap.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-73223373-1', 'auto');
  ga('send', 'pageview');
</script>




<meta name="generator" content="Hexo 5.0.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

 <body>  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav id="main-nav" class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/"></a>
      <div class="collapse navbar-collapse nav-menu">
		    <ul class="nav navbar-nav">
		      

          <!-- Categories -->
          
          <li>
            <a href="/" title="PytLab's Home" style="font-weight: normal; font-family: Calibri,Arial; font-size: 18px">
              <i class="fa fa-home"></i>Home
            </a>
          </li>
          
		      

          <!-- Categories -->
          
          <!-- Archives -->
          <li class="dropdown">
            <a href="/archives" class="dropdown-toggle" data-toggle="dropdown" title="All the articles." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
            <i class="fa fa-archive"></i>Archives
            <b class="caret"></b>   
            </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/archives" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Archives</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/2020/08/09/Life-of-a-thread/" style="font-size: 15px; font-family: 微软雅黑">Life of a thread<span></span></a></li>
              
              <li><a href="/2020/03/08/A-new-start/" style="font-size: 15px; font-family: 微软雅黑">I&#39;m back<span></span></a></li>
              
              <li><a href="/2018/03/07/遗传算法框架GAFT支持自定义个体编码方式/" style="font-size: 15px; font-family: 微软雅黑">遗传算法框架GAFT已支持自定义编码方式<span></span></a></li>
              
              <li><a href="/2018/01/27/实现属于自己的TensorFlow-三-反向传播与梯度下降算法实现/" style="font-size: 15px; font-family: 微软雅黑">实现属于自己的TensorFlow(三) - 反向传播...<span></span></a></li>
              
              <li><a href="/2018/01/25/实现属于自己的TensorFlow-二-梯度计算与反向传播/" style="font-size: 15px; font-family: 微软雅黑">实现属于自己的TensorFlow(二) - 梯度计算...<span></span></a></li>
              
              <li><a href="/2018/01/24/实现属于自己的TensorFlow-一-计算图与前向传播/" style="font-size: 15px; font-family: 微软雅黑">实现属于自己的TensorFlow(一) - 计算图与...<span></span></a></li>
              
              <li><a href="/2017/11/03/机器学习算法实践-树回归/" style="font-size: 15px; font-family: 微软雅黑">机器学习算法实践-树回归<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
          </li>

          
		      

          <!-- Categories -->
          
		      <li class="dropdown">
            <a href="/categories" class="dropdown-toggle" data-toggle="dropdown" title="All the categories." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
		    	  <i class="fa fa-folder"></i>Categories
            <b class="caret"></b>   
		    	  </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/categories" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Categories</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/categories/学习小结/" style="font-size: 15px; font-family: 微软雅黑">学习小结<span></span></a></li>
              
              <li><a href="/categories/学术/" style="font-size: 15px; font-family: 微软雅黑">学术<span></span></a></li>
              
              <li><a href="/categories/代码作品/" style="font-size: 15px; font-family: 微软雅黑">代码作品<span></span></a></li>
              
              <li><a href="/categories/我的日常/" style="font-size: 15px; font-family: 微软雅黑">我的日常<span></span></a></li>
              
              <li><a href="/categories/教程/" style="font-size: 15px; font-family: 微软雅黑">教程<span></span></a></li>
              
              <li><a href="/categories/译文/" style="font-size: 15px; font-family: 微软雅黑">译文<span></span></a></li>
              
              <li><a href="/categories/随笔/" style="font-size: 15px; font-family: 微软雅黑">随笔<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
		      </li>

          
		      

          <!-- Categories -->
          
          <!-- Tags -->
          <li class="dropdown">
            <a href="/tags" class="dropdown-toggle" data-toggle="dropdown" title="All the tags." style="font-weight: normal; font-family: Calibri,Arial; font-size:     18px">
            <i class="fa fa-tags"></i>Tags
            <b class="caret"></b>   
            </a>
            <ul class="dropdown-menu">
              <li class="divider"></li>
              <li><a href="/tags" style="font-size: 20px; font-family: 'Calibri Light',Arial">All Tags</a><span></span></li>
              <li class="divider"></li>
              
              <li><a href="/tags/python/" style="font-size: 15px; font-family: 微软雅黑">python<span></span></a></li>
              
              <li><a href="/tags/Cpp/" style="font-size: 15px; font-family: 微软雅黑">Cpp<span></span></a></li>
              
              <li><a href="/tags/catalysis/" style="font-size: 15px; font-family: 微软雅黑">catalysis<span></span></a></li>
              
              <li><a href="/tags/C/" style="font-size: 15px; font-family: 微软雅黑">C<span></span></a></li>
              
              <li><a href="/tags/chemistry/" style="font-size: 15px; font-family: 微软雅黑">chemistry<span></span></a></li>
              
              <li><a href="/tags/Parallel-Computing/" style="font-size: 15px; font-family: 微软雅黑">Parallel Computing<span></span></a></li>
              
              <li><a href="/tags/学术/" style="font-size: 15px; font-family: 微软雅黑">学术<span></span></a></li>
              
              <li class="divider"></li>
            </ul>
          </li>
          
          
		      

          <!-- Categories -->
          
          <li>
            <a href="/about" title="About me." style="font-weight: normal; font-family: Calibri,Arial; font-size: 18px">
              <i class="fa fa-user"></i>About
            </a>
          </li>
          
		      
		    </ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">		
			<h1> 实现属于自己的TensorFlow(一) - 计算图与前向传播</h1>
		</div>		
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <p>前段时间因为课题需要使用了一段时间TensorFlow，感觉这种框架很有意思，除了可以搭建复杂的神经网络，也可以优化其他自己需要的计算模型，所以一直想自己学习一下写一个类似的图计算框架。前几天组会开完决定着手实现一个模仿TensorFlow接口的简陋版本图计算框架以学习计算图程序的编写以及前向传播和反向传播的实现。目前实现了前向传播和反向传播以及梯度下降优化器，并写了个优化线性模型的例子。</p>
<p>代码放在了GitHub上，取名<em>SimpleFlow</em>, 仓库链接: <a target="_blank" rel="noopener" href="https://github.com/PytLab/simpleflow">https://github.com/PytLab/simpleflow</a></p>
<a id="more"></a>
<p>虽然前向传播反向传播这些原理了解起来并不是很复杂，但是真正着手写起来才发现,里面还是有很多细节需要学习和处理才能对实际的模型进行优化(例如Loss函数对每个计算节点矩阵求导的处理)。其中SimpleFlow的代码并没有考虑太多的东西比如<code>dtype</code>和张量<code>size</code>的检查等，因为只是为了实现主要图计算功能并没有考虑任何的优化, 内部张量运算使用的Numpy的接口(毕竟是学习和练手的目的嘛)。好久时间没更新博客了，在接下来的几篇里面我将把实现的过程的细节总结一下，希望可以给后面学习的童鞋做个参考。</p>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>本文主要介绍计算图以及前向传播的实现, 主要涉及<strong>图的构建</strong>以及通过对构建好的图进行<strong>后序遍历</strong>然后进行前向传播计算得到具体节点上的输出值。</p>
<p>先贴上一个简单的实现效果吧:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> simpleflow <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a graph</span></span><br><span class="line"><span class="keyword">with</span> sf.Graph().as_default():</span><br><span class="line">    a = sf.constant(<span class="number">1.0</span>, name=<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">    b = sf.constant(<span class="number">2.0</span>, name=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    result = sf.add(a, b, name=<span class="string">&#x27;result&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a session to compute</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(sess.run(result))</span><br></pre></td></tr></table></figure></p>
<h2 id="计算图-Computational-Graph"><a href="#计算图-Computational-Graph" class="headerlink" title="计算图(Computational Graph)"></a>计算图(Computational Graph)</h2><p>计算图是计算代数中的一个基础处理方法，我们可以通过一个有向图来表示一个给定的数学表达式，并可以根据图的特点快速方便对表达式中的变量进行求导。而神经网络的本质就是一个多层复合函数, 因此也可以通过一个图来表示其表达式。</p>
<p>本部分主要总结计算图的实现，在计算图这个有向图中，每个节点代表着一种特定的运算例如求和，乘积，向量乘积，平方等等… 例如求和表达式$f(x, y) = x + y$使用有向图表示为:</p>
<p><img src="/assets/images/blog_img/2018-01-24-实现属于自己的TensorFlow-一-计算图与前向传播/addition.png" alt=""></p>
<p>表达式$f(x, y, z) = z(x+y)$使用有向图表示为:</p>
<p><img src="/assets/images/blog_img/2018-01-24-实现属于自己的TensorFlow-一-计算图与前向传播/multiplication.png" alt=""></p>
<p>与TensorFlow的实现不同，为了简化，在SimpleFlow中我并没有定义<code>Tensor</code>类来表示计算图中节点之间的数据流动，而是<strong>直接定义节点的类型</strong>，其中主要定义了四种类型来表示图中的节点:</p>
<ol>
<li><code>Operation</code>: 操作节点主要接受一个或者两个输入节点然后进行简单的操作运算，例如上图中的加法操作和乘法操作等。</li>
<li><code>Variable</code>: 没有输入节点的节点，此节点包含的数据在运算过程中是可以变化的。</li>
<li><code>Constant</code>: 类似<code>Variable</code>节点，也没有输入节点，此节点中的数据在图的运算过程中不会发生变化</li>
<li><code>Placeholder</code>: 同样没有输入节点，此节点的数据是通过图建立好以后通过用户传入的</li>
</ol>
<p>其实图中的所有节点都可以看成是某种操作，其中<code>Variable</code>, <code>Constant</code>, <code>Placeholder</code>都是一种特殊的操作，只是相对于普通的<code>Operation</code>而言，他们没有输入，但是都会有输出（像上图中的$x$, $y$节点，他们本身输出自身的值到$+$节点中去），通常会输出到<code>Operation</code>节点，进行进一步的计算。</p>
<p>下面我们主要介绍如何实现计算图的基本组件: 节点和边。</p>
<h3 id="Operation节点"><a href="#Operation节点" class="headerlink" title="Operation节点"></a><code>Operation</code>节点</h3><p>节点表示操作，边代表节点接收和输出的数据，操作节点需要含有以下属性:</p>
<ol>
<li><code>input_nodes</code>: 输入节点，里面存放与当前节点相连接的输入节点的引用</li>
<li><code>output_nodes</code>: 输出节点, 存放以当前节点作为输入的节点，也就是当前节点的去向</li>
<li><code>output_value</code>: 存储当前节点的数值, 如果是<code>Add</code>节点，此变量就存储两个输入节点<code>output_value</code>的和</li>
<li><code>name</code>: 当前节点的名称</li>
<li><code>graph</code>: 此节点所属的图</li>
</ol>
<p>下面我们定义了<code>Operation</code>基类用于表示图中的操作节点(详见<a target="_blank" rel="noopener" href="https://github.com/PytLab/simpleflow/blob/master/simpleflow/operations.py">https://github.com/PytLab/simpleflow/blob/master/simpleflow/operations.py</a>):<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Operation</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Base class for all operations in simpleflow.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    An operation is a node in computational graph receiving zero or more nodes</span></span><br><span class="line"><span class="string">    as input and produce zero or more nodes as output. Vertices could be an</span></span><br><span class="line"><span class="string">    operation, variable or placeholder.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *input_nodes, name=None</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Operation constructor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param input_nodes: Input nodes for the operation node.</span></span><br><span class="line"><span class="string">        :type input_nodes: Objects of `Operation`, `Variable` or `Placeholder`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param name: The operation name.</span></span><br><span class="line"><span class="string">        :type name: str.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># Nodes received by this operation.</span></span><br><span class="line">        self.input_nodes = input_nodes</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Nodes that receive this operation node as input.</span></span><br><span class="line">        self.output_nodes = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Output value of this operation in session execution.</span></span><br><span class="line">        self.output_value = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Operation name.</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Graph the operation belongs to.</span></span><br><span class="line">        self.graph = DEFAULT_GRAPH</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add this operation node to destination lists in its input nodes.</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> input_nodes:</span><br><span class="line">            node.output_nodes.append(self)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add this operation to default graph.</span></span><br><span class="line">        self.graph.operations.append(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Compute and return the output value of the operation.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_gradient</span>(<span class="params">self, grad=None</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Compute and return the gradient of the operation wrt inputs.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure><br>在初始化方法中除了定义上面提到的属性外，还需要进行两个操作:</p>
<ol>
<li>将当前节点的引用添加到他输入节点的<code>output_nodes</code>这样可以在输入节点中找到当前节点。</li>
<li>将当前节点的引用添加到图中，方便后面对图中的资源进行回收等操作</li>
</ol>
<p>另外，每个操作节点还有两个必须的方法: <code>comput_output</code>和<code>compute_gradient</code>. 他们分别负责根据输入节点的值计算当前节点的输出值和根据操作属性和当前节点的值计算梯度。关于梯度的计算将在后续的文章中详细介绍，本文只对节点输出值的计算进行介绍。</p>
<p>下面我以<strong>求和</strong>操作为例来说明具体操作节点的实现:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Add</span>(<span class="params">Operation</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; An addition operation.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x, y, name=None</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Addition constructor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param x: The first input node.</span></span><br><span class="line"><span class="string">        :type x: Object of `Operation`, `Variable` or `Placeholder`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param y: The second input node.</span></span><br><span class="line"><span class="string">        :type y: Object of `Operation`, `Variable` or `Placeholder`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param name: The operation name.</span></span><br><span class="line"><span class="string">        :type name: str.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        super(self.__class__, self).__init__(x, y, name=name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Compute and return the value of addition operation.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        x, y = self.input_nodes</span><br><span class="line">        self.output_value = np.add(x.output_value, y.output_value)</span><br><span class="line">        <span class="keyword">return</span> self.output_value</span><br></pre></td></tr></table></figure></p>
<p>可见，计算当前节点<code>output_value</code>的值的<strong>前提条件</strong>就是<strong>他的输入节点的值在此之前已经计算得到了</strong>。</p>
<h3 id="Variable节点"><a href="#Variable节点" class="headerlink" title="Variable节点"></a><code>Variable</code>节点</h3><p>与<code>Operation</code>节点类似，<code>Variable</code>节点也需要<code>output_value</code>, <code>output_nodes</code>等属性，但是它没有输入节点，也就没有<code>input_nodes</code>属性了，而是需要在创建的时候确定一个初始值<code>initial_value</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Variable</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Variable node in computational graph.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, initial_value=None, name=None, trainable=True</span>):</span> </span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Variable constructor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param initial_value: The initial value of the variable.</span></span><br><span class="line"><span class="string">        :type initial_value: number or a ndarray.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param name: Name of the variable.</span></span><br><span class="line"><span class="string">        :type name: str.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># Variable initial value.</span></span><br><span class="line">        self.initial_value = initial_value</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Output value of this operation in session execution.</span></span><br><span class="line">        self.output_value = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Nodes that receive this variable node as input.</span></span><br><span class="line">        self.output_nodes = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Variable name.</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Graph the variable belongs to.</span></span><br><span class="line">        self.graph = DEFAULT_GRAPH</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add to the currently active default graph.</span></span><br><span class="line">        self.graph.variables.append(self)</span><br><span class="line">        <span class="keyword">if</span> trainable:</span><br><span class="line">            self.graph.trainable_variables.append(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Compute and return the variable value.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> self.output_value <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.output_value = self.initial_value</span><br><span class="line">        <span class="keyword">return</span> self.output_value</span><br></pre></td></tr></table></figure>
<h3 id="Constant节点和Placeholder节点"><a href="#Constant节点和Placeholder节点" class="headerlink" title="Constant节点和Placeholder节点"></a><code>Constant</code>节点和<code>Placeholder</code>节点</h3><p><code>Constant</code>和<code>Placeholder</code>节点与<code>Variable</code>节点类似，具体实现详见: <a target="_blank" rel="noopener" href="https://github.com/PytLab/simpleflow/blob/master/simpleflow/operations.py">https://github.com/PytLab/simpleflow/blob/master/simpleflow/operations.py</a></p>
<h3 id="计算图对象"><a href="#计算图对象" class="headerlink" title="计算图对象"></a>计算图对象</h3><p>在定义了图中的节点后我们需要将定义好的节点放入到一个图中统一保管，因此就需要定义一个<code>Graph</code>类来存放创建的节点，方便统一操作图中节点的资源。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Graph containing all computing nodes.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Graph constructor.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.operations, self.constants, self.placeholders = [], [], []</span><br><span class="line">        self.variables, self.trainable_variables = [], []</span><br></pre></td></tr></table></figure>
<p>为了提供一个默认的图，在导入simpleflow模块的时候创建一个全局变量来引用默认的图:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> .graph <span class="keyword">import</span> Graph</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a default graph.</span></span><br><span class="line"><span class="keyword">import</span> builtins</span><br><span class="line">DEFAULT_GRAPH = builtins.DEFAULT_GRAPH = Graph()</span><br></pre></td></tr></table></figure>
<p>为了模仿TensorFlow的接口，我们给<code>Graph</code>添加上下文管理器协议方法使其成为一个上下文管理器, 同时也添加一个<code>as_default</code>方法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__enter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Reset default graph.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">global</span> DEFAULT_GRAPH</span><br><span class="line">        self.old_graph = DEFAULT_GRAPH</span><br><span class="line">        DEFAULT_GRAPH = self</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__exit__</span>(<span class="params">self, exc_type, exc_value, exc_tb</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Recover default graph.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">global</span> DEFAULT_GRAPH</span><br><span class="line">        DEFAULT_GRAPH = self.old_graph</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">as_default</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Set this graph as global default graph.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure>
<p>这样在进入<code>with</code>代码块之前先保存旧的默认图对象然后将当前图赋值给全局图对象，这样<code>with</code>代码块中的节点默认会添加到当前的图中。最后退出<code>with</code>代码块时再对图进行恢复即可。这样我们可以按照TensorFlow的方式来在某个图中创建节点.</p>
<p>Ok，根据上面的实现我们已经可以创建一个计算图了:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> simpleflow <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> sf.Graph().as_default():</span><br><span class="line">    a = sf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>], name=<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">    b = sf.constant(<span class="number">2.0</span>, name=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    c = a * b</span><br></pre></td></tr></table></figure></p>
<h2 id="前向传播-Feedforward"><a href="#前向传播-Feedforward" class="headerlink" title="前向传播(Feedforward)"></a>前向传播(Feedforward)</h2><p>实现了计算图和图中的节点，我们需要对计算图进行计算, 本部分对计算图的前向传播的实现进行总结。</p>
<h3 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h3><p>首先，我们需要实现一个<code>Session</code>来对一个已经创建好的计算图进行计算，因为当我们创建我们之前定义的节点的时候其实只是创建了一个空节点，节点中并没有数值可以用来计算，也就是<code>output_value</code>是空的。为了模仿TensorFlow的接口，我们在这里也把session定义成一个上下文管理器:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Session</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; A session to compute a particular graph.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Session constructor.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># Graph the session computes for.</span></span><br><span class="line">        self.graph = DEFAULT_GRAPH</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__enter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Context management protocal method called before `with-block`.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__exit__</span>(<span class="params">self, exc_type, exc_value, exc_tb</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Context management protocal method called after `with-block`.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Free all output values in nodes.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        all_nodes = (self.graph.constants + self.graph.variables +</span><br><span class="line">                     self.graph.placeholders + self.graph.operations +</span><br><span class="line">                     self.graph.trainable_variables)</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> all_nodes:</span><br><span class="line">            node.output_value = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, operation, feed_dict=None</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Compute the output of an operation.&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<h3 id="计算某个节点的输出值"><a href="#计算某个节点的输出值" class="headerlink" title="计算某个节点的输出值"></a>计算某个节点的输出值</h3><p>上面我们已经可以构建出一个计算图了，计算图中的每个节点与其相邻的节点有方向的联系起来，现在我们需要根据图中节点的关系来推算出某个节点的值。那么如何计算呢? 还是以我们刚才$f(x, y, z) = z(x + y)$的计算图为例,<br><img src="/assets/images/blog_img/2018-01-24-实现属于自己的TensorFlow-一-计算图与前向传播/multiplication.png" alt=""></p>
<p>若我们需要计算橙色$\times$运算节点的输出值，我们需要计算与它相连的两个输入节点的输出值，进而需要计算绿色$+$的输入节点的输出值。我们可以通过后序遍历来获取计算一个节点所需的所有节点的输出值。为了方便实现，后序遍历我直接使用了递归的方式来实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_prerequisite</span>(<span class="params">operation</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Perform a post-order traversal to get a list of nodes to be computed in order.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    postorder_nodes = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Collection nodes recursively.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postorder_traverse</span>(<span class="params">operation</span>):</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(operation, Operation):</span><br><span class="line">            <span class="keyword">for</span> input_node <span class="keyword">in</span> operation.input_nodes:</span><br><span class="line">                postorder_traverse(input_node)</span><br><span class="line">        postorder_nodes.append(operation)</span><br><span class="line"></span><br><span class="line">    postorder_traverse(operation)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> postorder_nodes</span><br></pre></td></tr></table></figure>
<p>通过此函数我们可以获取计算一个节点值所需要所有节点列表，再依次计算列表中节点的输出值，最后便可以轻易的计算出当前节点的输出值了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Session</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, operation, feed_dict=None</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Compute the output of an operation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param operation: A specific operation to be computed.</span></span><br><span class="line"><span class="string">        :type operation: object of `Operation`, `Variable` or `Placeholder`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feed_dict: A mapping between placeholder and its actual value for the session.</span></span><br><span class="line"><span class="string">        :type feed_dict: dict.</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># Get all prerequisite nodes using postorder traversal.</span></span><br><span class="line">        postorder_nodes = _get_prerequisite(operation)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> postorder_nodes:</span><br><span class="line">            <span class="keyword">if</span> type(node) <span class="keyword">is</span> Placeholder:</span><br><span class="line">                node.output_value = feed_dict[node]</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># Operation and variable</span></span><br><span class="line">                node.compute_output()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> operation.output_value</span><br></pre></td></tr></table></figure>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>上面我们实现了计算图以及前向传播，我们就可以创建计算图计算表达式的值了, 如下:<br>$$<br>f = \left[ \begin{matrix}<br>1 &amp; 2 &amp; 3 \\<br>3 &amp; 4 &amp; 5 \\<br>\end{matrix} \right] \times<br>\left[ \begin{matrix}<br>9 &amp; 8 \\<br>7 &amp; 6 \\<br>10 &amp; 11 \\<br>\end{matrix} \right] + 3 =<br>\left[ \begin{matrix}<br>54 &amp; 54 \\<br>106 &amp; 104 \\<br>\end{matrix} \right]<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> simpleflow <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a graph</span></span><br><span class="line"><span class="keyword">with</span> sf.Graph().as_default():</span><br><span class="line">    w = sf.constant([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]], name=<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    x = sf.constant([[<span class="number">9</span>, <span class="number">8</span>], [<span class="number">7</span>, <span class="number">6</span>], [<span class="number">10</span>, <span class="number">11</span>]], name=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    b = sf.constant(<span class="number">1.0</span>, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    result = sf.matmul(w, x) + b</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a session to compute</span></span><br><span class="line">    <span class="keyword">with</span> sf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        print(sess.run(result))</span><br></pre></td></tr></table></figure>
<p>输出值:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[  <span class="number">54.</span>,   <span class="number">54.</span>],</span><br><span class="line">       [ <span class="number">106.</span>,  <span class="number">104.</span>]])</span><br></pre></td></tr></table></figure></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文使用Python实现了计算图以及计算图的前向传播，并模仿TensorFlow的接口创建了<code>Session</code>以及<code>Graph</code>对象。下篇中将继续总结计算图节点计算梯度的方法以及反向传播和梯度下降优化器的实现。</p>
<p>最后再附上simpleflow项目的链接, 欢迎相互学习和交流: <a target="_blank" rel="noopener" href="https://github.com/PytLab/simpleflow">https://github.com/PytLab/simpleflow</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a target="_blank" rel="noopener" href="http://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/">Deep Learning From Scratch</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Tree_traversal#Post-order">https://en.wikipedia.org/wiki/Tree_traversal#Post-order</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25496760">https://zhuanlan.zhihu.com/p/25496760</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/magic_anthony/article/details/77531552">http://blog.csdn.net/magic_anthony/article/details/77531552</a></li>
</ul>
	  
	</div>

    
	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
				
    	<li class="prev"><a href="/2018/01/25/实现属于自己的TensorFlow-二-梯度计算与反向传播/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
  		

        <li><a href="/"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2017/11/03/机器学习算法实践-树回归/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>
    
	
    <!-- bdshare -->
    
        
    <div class="bdsharebuttonbox">
        <a href="#" class="bds_more" data-cmd="more"></a>
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
        <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
        <a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
        <a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
        <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
    </div>
    <script>
        window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};
        with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>


        

    

	<!-- comment -->
    
<section id="comment">
  <h2 class="title">Comments</h2>

  
  	 <div id="disqus_thread">
     <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  	 </div>
  
</section>

	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2018-01-24 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/代码作品/">代码作品<span class="badge">19</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/MachineLearning/">MachineLearning<span class="badge">16</span></a></li> <li><a href="/tags/TensorFlow/">TensorFlow<span class="badge">3</span></a></li> <li><a href="/tags/SimpleFlow/">SimpleFlow<span class="badge">3</span></a></li> <li><a href="/tags/NeuralNetwork/">NeuralNetwork<span class="badge">3</span></a></li> <li><a href="/tags/DeepLearning/">DeepLearning<span class="badge">3</span></a></li> <li><a href="/tags/ComputationGraph/">ComputationGraph<span class="badge">1</span></a></li> <li><a href="/tags/Feedfoward/">Feedfoward<span class="badge">1</span></a></li>

    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	   <a data-toggle="collapse" data-target="#toc"><i class="fa fa-bars"></i></a>
	   <div id="toc" class="toc collapse in">
			<ol class="toc-article"><li class="toc-article-item toc-article-level-1"><a class="toc-article-link" href="#%E6%AD%A3%E6%96%87"><span class="toc-article-text">正文</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E8%AE%A1%E7%AE%97%E5%9B%BE-Computational-Graph"><span class="toc-article-text">计算图(Computational Graph)</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#Operation%E8%8A%82%E7%82%B9"><span class="toc-article-text">Operation节点</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#Variable%E8%8A%82%E7%82%B9"><span class="toc-article-text">Variable节点</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#Constant%E8%8A%82%E7%82%B9%E5%92%8CPlaceholder%E8%8A%82%E7%82%B9"><span class="toc-article-text">Constant节点和Placeholder节点</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#%E8%AE%A1%E7%AE%97%E5%9B%BE%E5%AF%B9%E8%B1%A1"><span class="toc-article-text">计算图对象</span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD-Feedforward"><span class="toc-article-text">前向传播(Feedforward)</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#%E4%BC%9A%E8%AF%9D"><span class="toc-article-text">会话</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#%E8%AE%A1%E7%AE%97%E6%9F%90%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E8%BE%93%E5%87%BA%E5%80%BC"><span class="toc-article-text">计算某个节点的输出值</span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#%E4%BE%8B%E5%AD%90"><span class="toc-article-text">例子</span></a></li></ol></li><li class="toc-article-item toc-article-level-1"><a class="toc-article-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-article-text">总结</span></a></li><li class="toc-article-item toc-article-level-1"><a class="toc-article-link" href="#%E5%8F%82%E8%80%83"><span class="toc-article-text">参考</span></a></li></ol>
		</div>
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->

<script type="text/javascript">
var disqus_shortname = 'pytlab';
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  
  &copy; copyright 2020 by <a href="http://pytlab.github.io"> PytLab </a>
  
      &nbsp; <a target="_blank" rel="noopener" href="http://github.com/PytLab/hexo-theme-freemind/">Theme</a> by <a href="http://pytlab.github.io/">PytLab</a> based on <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({{ JSON.stringify(config) }});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="{{ src }}">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



</body>
   </html>
